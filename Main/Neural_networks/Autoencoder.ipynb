{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP AUTOENCODER WITH KERAS\n",
    "\n",
    "Autoencoders are a popular class of Deep Neural Networks that are capable of learning representations in a self-supervised way. We will build one with Keras.\n",
    "\n",
    "**a) Fetch the MNIST dataset ([https://www.tensorflow.org/api\\_docs/python/tf/keras/datasets/mnist/load\\_data](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data)) with Keras and scale the data to \\[0,1].**\n",
    "\n",
    "**b) Build a convolutional autoencoder model consisting of encoder and decoder.**\n",
    "\n",
    "*   The encoder and decoder are structured in symmetrical fashion, i.e., both parts use the same layer structure.\n",
    "*   The encoder uses two convolutional layers (64 and 32 filters) followed by a flattening layer and a dense layer. The number of neurons of this dense layer defines the encoded vector size of the input image. Set it to 64. Use parameters of your choice for all other layers.\n",
    "*   The decoder transforms the input data, i.e., the encoded vector coming from the encoder, in reverse order compared to the encoder. An upscaling dense layer followed by two deconvolutional (transposed) layers and a final convolutional layer with a single filter, all layers using similar parameters as the encoder layers.\n",
    "*   Explain the purpose of the individual layers and how the input shapes change during the transformations of these layers.\n",
    "\n",
    "**c) Train this model using a binary cross-entropy loss for three epochs. Use the SGD optimizer with a learning rate of 1.5.**\n",
    "\n",
    "**d) Select five random images from the test set and compare the visualizations of the original and the auto-encoded images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (48000, 28, 28, 1), Test shape: (12000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "# Load the MNIST dataset\n",
    "data = mnist.load_data()\n",
    "X = data[0][0]\n",
    "y = data[0][1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the data to the range [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape data to include channel dimension\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "print(f\"Train shape: {x_train.shape}, Test shape: {x_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1568)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                100416    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              101920    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 32)       9248      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 64)       18496     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 249,761\n",
      "Trainable params: 249,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# b)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Conv2DTranspose, Reshape\n",
    "\n",
    "# Encoder\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "# Encoder layers\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "encoded = Dense(64, activation='relu')(x)\n",
    "\n",
    "# Decoder layers\n",
    "x = Dense(7 * 7 * 32, activation='relu')(encoded)\n",
    "x = Reshape((7, 7, 32))(x)\n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu', strides=(2, 2), padding='same')(x)\n",
    "x = Conv2DTranspose(64, (3, 3), activation='relu', strides=(2, 2), padding='same')(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='SGD', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.3870WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\Data science\\Python materials\\Machine learning\\Machine-learning\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1557, in test_function  *\n        return step_function(self, iterator)\n    File \"d:\\Data science\\Python materials\\Machine learning\\Machine-learning\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1546, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Data science\\Python materials\\Machine learning\\Machine-learning\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1535, in run_step  **\n        outputs = model.test_step(data)\n    File \"d:\\Data science\\Python materials\\Machine learning\\Machine-learning\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1499, in test_step\n        y_pred = self(x, training=False)\n    File \"d:\\Data science\\Python materials\\Machine learning\\Machine-learning\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Data science\\Python materials\\Machine learning\\Machine-learning\\.venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model\" (type Functional).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 1)\n    \n    Call arguments received by layer \"model\" (type Functional):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Data science\\Python materials\\Machine learning\\Machine-learning\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file9vkk30g5.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\Data science\\Python materials\\Machine learning\\Machine-learning\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1557, in test_function  *\n        return step_function(self, iterator)\n    File \"d:\\Data science\\Python materials\\Machine learning\\Machine-learning\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1546, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Data science\\Python materials\\Machine learning\\Machine-learning\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1535, in run_step  **\n        outputs = model.test_step(data)\n    File \"d:\\Data science\\Python materials\\Machine learning\\Machine-learning\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1499, in test_step\n        y_pred = self(x, training=False)\n    File \"d:\\Data science\\Python materials\\Machine learning\\Machine-learning\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Data science\\Python materials\\Machine learning\\Machine-learning\\.venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model\" (type Functional).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 1)\n    \n    Call arguments received by layer \"model\" (type Functional):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# c)\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Set the optimizer with a learning rate of 1.5\n",
    "optimizer = SGD(learning_rate=1.5)\n",
    "autoencoder.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "\n",
    "# Train the model\n",
    "autoencoder.fit(x_train, x_train, epochs=3, batch_size=256, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DENOISING AUTOENCODER WITH KERAS\n",
    "\n",
    "In this exercise, we will use autoencoders for the purpose of denoising data. The approach will be similar to that of Exercise 1.\n",
    "\n",
    "**a) Load the MNIST dataset and scale it to \\[0,1].**\n",
    "\n",
    "**b) Build an autoencoder model of your choice. The encoder must produce vectorial representations of size 64. You can use a convolution model as in Exercise 1 or use a simple model of dense layers.**\n",
    "\n",
    "**c) Add three different forms of noise to the training and test data (one noisy dataset for each type of noise). Make sure that the resulting images are still in the range \\[0,1]. Also, use a method that allows a factor to control the amount of noise that is added. Use 0.25 as the value for tests:**\n",
    "\n",
    "1.  Gaussian noise with a mean of 0.0 and a standard deviation of 1.0.\n",
    "2.  Uniform noise from a range of \\[0,1].\n",
    "3.  Noise in the form of merged images. Apply noise to one image by merging it with another random image from the examples.\n",
    "\n",
    "**d) Train your model for three epochs using a suitable loss function.**\n",
    "\n",
    "*   Use a combined dataset with all noisy examples as input data and use the original examples as target data.\n",
    "*   Use the SGD optimizer with a learning rate of 1.5.\n",
    "\n",
    "**e) After training, visualize the model’s performance on a single digit. Display the original image, all three noisy variants, and the denoised image.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# SUPERVISED REPRESENTATION LEARNING\n",
    "\n",
    "In contrast to the exercises from before, learning representations can also be done supervised. This is especially useful in scenarios where labels for similar data instances exist that can guide the learning process.\n",
    "\n",
    "**a) Load the MNIST dataset and scale the data to the range \\[0,1].**\n",
    "\n",
    "**b) Prepare a training data generator ([https://www.tensorflow.org/api\\_docs/python/tf/data/Dataset#from\\_generator](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator)). Each training instance is put together from two images and a label that is either 1 or 0. Randomly, generate training instances by putting together two images of the same class (with label 1) or two random images (with label 0).**\n",
    "\n",
    "**c) Build a model using the Functional API of TensorFlow ([https://www.tensorflow.org/guide/keras/functional](https://www.tensorflow.org/guide/keras/functional)).** \n",
    "\n",
    "*   The model should have a sub-model that transforms a single image into a representation of size 64. \n",
    "*   The main model should take the pairs of images and transform both of them to their vector representation using the same sub-model. Afterward, a pairwise dot product should be computed for the vector pair. This dot product is the final output.\n",
    "\n",
    "**d) Train the model with the priorly created generator for five epochs, using hinge loss.**\n",
    "\n",
    "*   Why is this loss function used?\n",
    "*   How does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCEMENT LEARNING FROM SCRATCH\n",
    "\n",
    "In this exercise, we will build up a Reinforcement Learning (RL) process. We will train a model to help us play Tic Tac Toe. Use the provided class `tic_tac_toe.py` for this exercise.\n",
    "\n",
    "**a) Get familiar with the provided class `TicTacToe` by creating a game and playing a few rounds with random choices. The AI player is supposed to be the player 'o'.**\n",
    "\n",
    "**b) Collect the information of 1000 games that can be used to train a model later on:**\n",
    "\n",
    "*   Set up a loop that plays 1000 games.\n",
    "*   Each game is played by both players alternating. Player 'x' (You) always begins with a random play. Afterward, player 'o' makes its random move.\n",
    "*   For each of your turns, i.e., the turns of player 'x', store the board state before the turn and the cell that was chosen (information is returned by the random play method and can be retrieved from the board object).\n",
    "*   Always check if the game is finished after a player’s turn and if so, compute the rewards for this game (use the provided function `get_rewards()` in the file). This method expects the winner of the game as a parameter and a list of player x’s plays as tuples of chosen cell and board state before play.\n",
    "\n",
    "**c) The rewards are given by this function as a tuple where the first value is the rewards (target) and the second value is the training data in the form of chosen cell and board state.**\n",
    "\n",
    "*   Train a model of your choice (can be a Deep Learning Model or another model) to predict the expected reward given the provided training data.\n",
    "*   Split the available data before training (test ratio of 0.2).\n",
    "\n",
    "**d) Evaluate the trained model on the test set in terms of prediction deviation. Explain how the trained model could be used to help human players win Tic Tac Toe games.**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
